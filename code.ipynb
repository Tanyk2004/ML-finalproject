{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Final Project\n",
    "\n",
    "### Tanay, Vishal, Nikshita, Garv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.11/site-packages (3.9.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.11/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn matplotlib numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import sklearn \n",
    "from pandas import DataFrame\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "labels = df['Transported']\n",
    "features = df.drop(columns=['Transported'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaN: 2087\n",
      "Rows without NaN: 6606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Based on the results of our data exploration, we have decided to process the \\n    data in the following ways:\\n    We will drop the 2087 records with NaNs as there would still be 6606 records \\n    left, which seems sufficient to train a model with. We will revisit this if \\n    necessary.\\n    We will one hot encode the HomePlanet and Destination fields as they are \\n    categorical. \\n    We will drop the Name field since it is unique (or near unique) for each passenger,\\n    and it seems unlikely it could provide useful information.\\n    As the Cabin field essentially has three pieces of information (deck, number,\\n    and side), we have elected to break it down into three fields.\\n    Similarly, as the Passenger_Id field has two pieces of information (group number\\n    and passenger number), we will break it down into two fields.\\n    We will one hot encode the deck as it has\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Exploration\n",
    "\n",
    "# Checking how many NaNs there are \n",
    "rows_with_nan = features.isnull().any(axis=1).sum()\n",
    "rows_without_nan = len(features) - rows_with_nan\n",
    "\n",
    "print(f\"Rows with NaN: {rows_with_nan}\")\n",
    "print(f\"Rows without NaN: {rows_without_nan}\")\n",
    "\n",
    "# Checking what the data looks like\n",
    "features.head()\n",
    "\n",
    "''' Based on the results of our data exploration, we have decided to process the \n",
    "    data in the following ways:\n",
    "    We will drop the 2087 records with NaNs as there would still be 6606 records \n",
    "    left, which seems sufficient to train a model with. We will revisit this if \n",
    "    necessary.\n",
    "    We will one hot encode the HomePlanet and Destination fields as they are \n",
    "    categorical. \n",
    "    We will drop the Name field since it is unique (or near unique) for each passenger,\n",
    "    and it seems unlikely it could provide useful information.\n",
    "    As the Cabin field essentially has three pieces of information (deck, number,\n",
    "    and side), we have elected to break it down into three fields.\n",
    "    Similarly, as the Passenger_Id field has two pieces of information (group number\n",
    "    and passenger number), we will break it down into two fields.\n",
    "    We will one hot encode the deck as it has only a handful of options.\n",
    "    We will convert the new side feature from P or S into True or False.\n",
    "    For all numeric features (RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\n",
    "    Age, Room, Group, PassengerNumber), we will standardize the values so that \n",
    "    we can conduct PCA.\n",
    "    Lastly, we will conduct PCA on the data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Dropped Records:  2087\n",
      "Number of Records Left:  6606\n",
      "Original data shape: (6606, 26)\n",
      "Transformed data shape: (6606, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Room</th>\n",
       "      <th>Side</th>\n",
       "      <th>...</th>\n",
       "      <th>Destination_PSO J318.5-22</th>\n",
       "      <th>Destination_TRAPPIST-1e</th>\n",
       "      <th>Deck_A</th>\n",
       "      <th>Deck_B</th>\n",
       "      <th>Deck_C</th>\n",
       "      <th>Deck_D</th>\n",
       "      <th>Deck_E</th>\n",
       "      <th>Deck_F</th>\n",
       "      <th>Deck_G</th>\n",
       "      <th>Deck_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.695413</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.345756</td>\n",
       "      <td>-0.285355</td>\n",
       "      <td>-0.309494</td>\n",
       "      <td>-0.273759</td>\n",
       "      <td>-0.269534</td>\n",
       "      <td>-1.167051</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>-0.336769</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.176748</td>\n",
       "      <td>-0.279993</td>\n",
       "      <td>-0.266112</td>\n",
       "      <td>0.206165</td>\n",
       "      <td>-0.230494</td>\n",
       "      <td>-1.167051</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>2.002842</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.279083</td>\n",
       "      <td>1.845163</td>\n",
       "      <td>-0.309494</td>\n",
       "      <td>5.596357</td>\n",
       "      <td>-0.226058</td>\n",
       "      <td>-1.167051</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.282540</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.345756</td>\n",
       "      <td>0.479034</td>\n",
       "      <td>0.334285</td>\n",
       "      <td>2.636384</td>\n",
       "      <td>-0.098291</td>\n",
       "      <td>-1.167051</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>-0.887266</td>\n",
       "      <td>False</td>\n",
       "      <td>0.124056</td>\n",
       "      <td>-0.243650</td>\n",
       "      <td>-0.047470</td>\n",
       "      <td>0.220152</td>\n",
       "      <td>-0.267759</td>\n",
       "      <td>-1.165103</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CryoSleep       Age    VIP  RoomService  FoodCourt  ShoppingMall       Spa  \\\n",
       "0     False  0.695413  False    -0.345756  -0.285355     -0.309494 -0.273759   \n",
       "1     False -0.336769  False    -0.176748  -0.279993     -0.266112  0.206165   \n",
       "2     False  2.002842   True    -0.279083   1.845163     -0.309494  5.596357   \n",
       "3     False  0.282540  False    -0.345756   0.479034      0.334285  2.636384   \n",
       "4     False -0.887266  False     0.124056  -0.243650     -0.047470  0.220152   \n",
       "\n",
       "     VRDeck      Room   Side  ...  Destination_PSO J318.5-22  \\\n",
       "0 -0.269534 -1.167051   True  ...                      False   \n",
       "1 -0.230494 -1.167051  False  ...                      False   \n",
       "2 -0.226058 -1.167051  False  ...                      False   \n",
       "3 -0.098291 -1.167051  False  ...                      False   \n",
       "4 -0.267759 -1.165103  False  ...                      False   \n",
       "\n",
       "   Destination_TRAPPIST-1e  Deck_A  Deck_B  Deck_C  Deck_D  Deck_E  Deck_F  \\\n",
       "0                     True   False    True   False   False   False   False   \n",
       "1                     True   False   False   False   False   False    True   \n",
       "2                     True    True   False   False   False   False   False   \n",
       "3                     True    True   False   False   False   False   False   \n",
       "4                     True   False   False   False   False   False    True   \n",
       "\n",
       "   Deck_G  Deck_T  \n",
       "0   False   False  \n",
       "1   False   False  \n",
       "2   False   False  \n",
       "3   False   False  \n",
       "4   False   False  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# drop NaNs\n",
    "processed_features = features.dropna()\n",
    "print(\"Number of Dropped Records: \", len(features) - len(processed_features))\n",
    "print(\"Number of Records Left: \", len(processed_features))\n",
    "\n",
    "# Drop Name values\n",
    "processed_features = processed_features.drop(columns=['Name'])\n",
    "\n",
    "# Split Cabin values into three columns\n",
    "processed_features[[\"Deck\", \"Room\", \"Side\"]] = processed_features['Cabin'].str.split(\"/\", expand=True)\n",
    "processed_features = processed_features.drop(columns=['Cabin'])\n",
    "processed_features.head()\n",
    "\n",
    "# Split Passenger values into two columns\n",
    "processed_features[[\"Group\", \"Passenger_Number\"]] = processed_features['PassengerId'].str.split(\"_\", expand=True)\n",
    "processed_features = processed_features.drop(columns=['PassengerId'])\n",
    "processed_features.head()\n",
    "\n",
    "# One hot encode the HomePlanet\n",
    "processed_features = pd.get_dummies(processed_features, columns=[\"HomePlanet\"])\n",
    "\n",
    "# One hot encode the DestinationPlanet\n",
    "processed_features = pd.get_dummies(processed_features, columns=[\"Destination\"])\n",
    "\n",
    "# One hot encode the Deck\n",
    "processed_features = pd.get_dummies(processed_features, columns=[\"Deck\"])\n",
    "\n",
    "# convert Side to T or F\n",
    "processed_features[\"Side\"] = processed_features['Side'].map({'P': True, 'S' : False})\n",
    "\n",
    "# normalizing numeric features\n",
    "scaler = StandardScaler()\n",
    "processed_features['RoomService'] = scaler.fit_transform(processed_features[['RoomService']])\n",
    "processed_features['FoodCourt'] = scaler.fit_transform(processed_features[['FoodCourt']])\n",
    "processed_features['ShoppingMall'] = scaler.fit_transform(processed_features[['ShoppingMall']])\n",
    "processed_features['Spa'] = scaler.fit_transform(processed_features[['Spa']])\n",
    "processed_features['VRDeck'] = scaler.fit_transform(processed_features[['VRDeck']])\n",
    "processed_features['Age'] = scaler.fit_transform(processed_features[['Age']])\n",
    "processed_features['Room'] = scaler.fit_transform(processed_features[['Room']])\n",
    "processed_features['Group'] = scaler.fit_transform(processed_features[['Group']])\n",
    "processed_features['Passenger_Number'] = scaler.fit_transform(processed_features[['Passenger_Number']])\n",
    "\n",
    "pca = PCA(n_components=0.95, svd_solver='full')\n",
    "pca_data = pca.fit_transform(processed_features)\n",
    "pca_df = DataFrame(pca_data)\n",
    "\n",
    "print(\"Original data shape:\", processed_features.shape)\n",
    "print(\"Transformed data shape:\", pca_df.shape)\n",
    "\n",
    "processed_features.head()\n",
    "# pca_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
